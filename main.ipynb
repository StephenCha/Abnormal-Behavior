{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3b446a-f36f-46ff-b4b7-9dca78edbe14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# íŒêµ AI Challenge\n",
    "> ì°¸ì¹˜ê¹€ì¹˜ì°Œê°œíŒ€<br>\n",
    "> íŒ€ì¥ ì†ì°¬ì˜, íŒ€ì› ê¹€ë¯¼ì • ê¹€í•˜ë¦¼ ì´ë‘í˜„ ì°¨í˜„ìˆ˜\n",
    "* ê³¼ì œëª… : [ì•„ë™ ë° êµí†µì•½ì ë³´í˜¸ë¥¼ ìœ„í•œ ì–´ë¦°ì´ ë„ë¡œë³´í–‰ ìœ„í—˜í–‰ë™ ë¶„ë¥˜ ê³¼ì œ]\n",
    "* ê³¼ì œ ë§í¬ : https://www.aiconnect.kr/main/competition/privateDetail/200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c399d1e-7303-4345-a7ae-2cb65b7dd813",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342062d-42a6-49df-a478-880e685c1d1b",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30321103-75de-4d8d-815e-c066da74a9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import warnings\n",
    "\n",
    "import easydict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Others\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Customized Source Python Files\n",
    "import source.dataset as dataset\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score\n",
    "from source.model import C3D_model, R2Plus1D_model, R3D_model, Efficientnet_LSTM\n",
    "from source.model.utils.vit import TimeSformer\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dcbf89-ca95-4ab0-af6a-0bae98508f28",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d7d64-89ef-43fa-8da9-6c4cfd5c6ccb",
   "metadata": {},
   "source": [
    "## Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8f51f7-3dc6-4d72-97b9-9494f385784c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {\n",
    "        \"experiment\": \"exp1 TimeSformer\",  # ë§¤ë²ˆ ë°”ê¿”ì¤€ë‹¤.\n",
    "        \"wandb\": False,\n",
    "        \"randomseed\": False,\n",
    "        \"dataset\": \"kids\",  # Options: hmdb51 or ucf101 or `kids`\n",
    "        \"dataset_root_dir\": \"./dataset\",\n",
    "        \"project_dir\": os.getcwd(),\n",
    "        \"pretrained_model\": \"efficientnet_b4\", # ./pretrained/c3d-pretrained.pth, ./pretrained/TimeSformer_divST_96x4_224_K600.pyth, 'efficientnet_b4'\n",
    "        \"snapshot\": 20,  # Store a model every snapshot epochs\n",
    "        \"clip_len\": 16,\n",
    "        \"num_workers\": 4,\n",
    "        \"model\": \"Efficientnet_LSTM\",  # Options: C3D, R2Plus1D, R3D, TimeSformer, Efficientnet_LSTM\n",
    "        \"attention_type\": \"divided_space_time\",\n",
    "        \"num_frames\": 19,\n",
    "        \"img_size\": 224,\n",
    "        \"count\": 20,  # how many repeat for wandb\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss_function\": \"focal\",\n",
    "        \"schedular\": \"cosineannealingwarmrestarts\",\n",
    "        \"batch_size\": 20,\n",
    "    }\n",
    ")\n",
    "NAME_ELEMENTS = [args.model, time.strftime(\"%m%d_%H%M\", time.localtime(time.time()))]\n",
    "MODEL_NAME = \"_\".join(NAME_ELEMENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c96ba-54b1-4adf-a0b7-7c573a000900",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce28948-bf1e-46f5-80e1-59a3171c8711",
   "metadata": {},
   "source": [
    "## Randomseed & W and B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fec147-2cac-47a7-ac3a-67d5f69a6251",
   "metadata": {},
   "source": [
    "### ğŸš€ Setup\n",
    "\n",
    "Start out by installing the experiment tracking library and setting up your free W&B account:<br>\n",
    "`.login()` so you can log metrics to your projects<br>\n",
    "If you've never used Weights & Biases before,\n",
    "the call to `login` will give you a link to sign up for an account.\n",
    "W&B is free to use for personal and academic projects!<br>\n",
    "### ğŸ‘ˆ Pick a `method`\n",
    "The first thing we need to define is the `method`\n",
    "for choosing new parameter values.\n",
    "\n",
    "We provide the following search `methods`:\n",
    "*   **`grid` Search** â€“ Iterate over every combination of hyperparameter values.\n",
    "Very effective, but can be computationally costly.\n",
    "*   **`random` Search** â€“ Select each new combination at random according to provided `distribution`s. Surprisingly effective!\n",
    "*   **`bayesian` Search** â€“ Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.\n",
    "\n",
    "We'll stick with `random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700f2509-456d-4abe-85e6-93b2bfad33d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.randomseed:\n",
    "    torch.manual_seed(args.randomseed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(args.randomseed)\n",
    "    random.seed(args.randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aeeb8cb-089c-4f36-941b-8c34deb35273",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    #%%wandb\n",
    "    #%env WANDB_SILENT=True\n",
    "    #%env \"WANDB_NOTEBOOK_NAME\" \"main.ipynb\"\n",
    "    wandb.login()\n",
    "    sweep_config = {\n",
    "        \"name\": args.experiment,\n",
    "        \"method\": \"bayes\",  # grid, bayesian, random\n",
    "        \"metric\": {\n",
    "            \"name\": \"Weighted F1 Scrore\",\n",
    "            \"goal\": \"maximize\",\n",
    "            # 'target': 'goal value for the metric you're optimizing, for example : 0.01'\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            \"epochs\": {\"values\": [10, 15, 20]},\n",
    "            \"learning_rate\": {\"distribution\": \"uniform\", \"min\": 1e-4, \"max\": 1e-3,},\n",
    "            \"optimizer\": {\"values\": [\"adam\", \"sgd\", \"adamw\", \"adadelta\", \"nadam\"]},\n",
    "            \"loss_function\": {\"values\": [\"focal\", \"cross_entropy\", \"label_smooth\"]},\n",
    "            \"schedular\": {\n",
    "                \"values\": [\"step\", \"onecycle\", \"cosineannealingwarmrestarts\", \"swa\"]\n",
    "            },\n",
    "            \"batch_size\": {\"values\": [10, 15]},\n",
    "        },\n",
    "    }\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"tunakimchi\")\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"main.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2630c-ae35-4fab-955b-471ed3945dc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b9176-d0bb-4eae-8d56-508bc4c4f2ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce6b8e8-4f96-457f-b8ad-5bae1c3e4dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available else revert to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device being used:\", device)\n",
    "\n",
    "if args.dataset == \"hmdb51\":\n",
    "    num_classes = 51\n",
    "elif args.dataset == \"ucf101\":\n",
    "    num_classes = 101\n",
    "elif args.dataset == \"kids\":\n",
    "    num_classes = 9\n",
    "else:\n",
    "    print(\"We only implemented hmdb and ucf datasets.\")\n",
    "    raise NotImplementedError\n",
    "\n",
    "saveName = args.model + \"-\" + args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb3396b-b397-4c1f-ad5c-73760a8c1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build run dir\n",
    "runs = sorted(glob.glob(os.path.join(args.project_dir, \"run\", \"run_*\")))\n",
    "run_id = int(runs[-1].split(\"_\")[-1]) + 1 if runs else 0\n",
    "\n",
    "SAVE_DIR = os.path.join(args.project_dir, \"run\", \"run_\" + str(run_id))\n",
    "model_save_dir = os.path.join(SAVE_DIR, \"models\")\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c51ef8e-43b7-4f2f-b2f5-2dfcb43fe595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "if args.model == \"C3D\":\n",
    "    model = C3D_model.C3D(\n",
    "        model_dir=args.pretrained_model, num_classes=num_classes, pretrained=True\n",
    "    )\n",
    "\n",
    "elif args.model == \"R2Plus1D\":\n",
    "    model = R2Plus1D_model.R2Plus1DClassifier(\n",
    "        num_classes=num_classes, layer_sizes=(2, 2, 2, 2)\n",
    "    )\n",
    "elif args.model == \"R3D\":\n",
    "    model = R3D_model.R3DClassifier(num_classes=num_classes, layer_sizes=(2, 2, 2, 2))\n",
    "\n",
    "elif args.model == \"TimeSformer\":\n",
    "    model = TimeSformer(\n",
    "        img_size=args.img_size,\n",
    "        num_classes=num_classes,\n",
    "        num_frames=args.num_frames,\n",
    "        attention_type=args.attention_type,\n",
    "        pretrained_model=args.pretrained_model,\n",
    "    )\n",
    "\n",
    "elif args.model == \"Efficientnet_LSTM\":\n",
    "    model = Efficientnet_LSTM.net(pretrain_model=args.pretrained_model, embed_size=1280, LSTM_UNITS=64, DO=0.3)\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247d8a66-1376-4ac5-89a3-9676f357c79c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Efficientnet_LSTM from scratch...\n",
      "Total params: 4.84M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "net(\n",
       "  (cnn): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_fc): Linear(in_features=1280, out_features=9, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (lstm1): LSTM(1280, 64, batch_first=True, bidirectional=True)\n",
       "  (lstm2): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (linear_pe): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (linear_global): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training {} from scratch...\".format(args.model))\n",
    "print(\"Total params: %.2fM\" % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "# model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45ea77-50a9-47fd-97f5-d7a91a69794a",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bade0-24b9-4ba7-86b5-36832a4fe055",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37c179-0e8a-4a8b-bcf2-bb83af5c586c",
   "metadata": {},
   "source": [
    "* ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "ì›í™œí•œ ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµì„ ìœ„í•˜ì—¬ `dataset` ë””ë ‰í† ë¦¬ ì•ˆì— ë‹¤ìŒê³¼ ê°™ì´ ê²½ë¡œë¥¼ ì„¤ì •í•˜ì—¬ ë°ì´í„°ë¥¼ ì €ì¥í•´ì•¼í•œë‹¤.<br>\n",
    "train ë°ì´í„°ì…‹ì€ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë³„ë„ì˜ ë””ë ‰í† ë¦¬ì— ë¹„ë””ì˜¤ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì €ì¥í•´ì•¼ í•˜ëŠ”ë°, arrangement.ipynbë¥¼ ì´ìš©í•˜ë©´ ë°”ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥ì‹œì¼œì¤€ë‹¤.\n",
    "\n",
    "```\n",
    "dataset\n",
    "â”œâ”€â”€ label\n",
    "â”‚   â””â”€â”€ kids_labels\n",
    "â”œâ”€â”€ train\n",
    "â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0003.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”œâ”€â”€ fall_down\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0002.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ fighting\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0056.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   ...\n",
    "â””â”€â”€ test (ê³µê°œê°€ ì•ˆë˜ì–´ìˆë‹¤)\n",
    "    â”œâ”€â”€ test_0000.mp4\n",
    "    â”œâ”€â”€ test_0000.mp4\n",
    "    â”œâ”€â”€ test_0000.mp4\n",
    "    â”œâ”€â”€ ...\n",
    "```\n",
    "\n",
    "í•™ìŠµ ë° ì¶”ë¡  ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ê°ê° train_processed, test_processed ë””ë ‰í† ë¦¬ê°€ ë‹¤ìŒê³¼ ê°™ì´ ìƒì„±ëœë‹¤.<br>\n",
    "ì´ëŠ” dataset.pyë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ ë˜ë‚˜, êµ³ì´ í•  í•„ìš”ëŠ” ì—†ë‹¤.<br>\n",
    "ì „ì²˜ë¦¬ì—ì„œëŠ” ë¹„ë””ì˜¤ì—ì„œ 16í”„ë ˆì„ì„ ìƒ˜í”Œë§í•œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¹„ë””ì˜¤ íŒŒì¼ëª… ë””ë ‰í† ë¦¬ì— ë³„ë„ë¡œ ì €ì¥í•˜ëŠ” ê³¼ì •ì´ ìˆ˜í–‰ëœë‹¤.\n",
    "```\n",
    "dataset\n",
    "â”œâ”€â”€ label\n",
    "â”‚   â””â”€â”€ kids_labels\n",
    "â”œâ”€â”€ train\n",
    "â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0003.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”œâ”€â”€ fall_down\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0002.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ fighting\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0056.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   ...\n",
    "â”‚\n",
    "â”œâ”€â”€ train_processed\n",
    "â”‚   â”œâ”€â”€ train\n",
    "â”‚   â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ train_0003\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00000.jpg\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00001.jpg\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ val\n",
    "â”‚   â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ train_0004\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00000.jpg\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00001.jpg\n",
    "â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚\n",
    "â”œâ”€â”€ test\n",
    "â”‚   â”œâ”€â”€ test_0000.mp4\n",
    "â”‚   â”œâ”€â”€ test_0000.mp4\n",
    "â”‚   â”œâ”€â”€ test_0000.mp4\n",
    "â”‚   â””â”€â”€ ...\n",
    "â”‚\n",
    "â””â”€â”€ test_processed\n",
    "    â”œâ”€â”€ test_0000\n",
    "    â”‚   â”œâ”€â”€ 00000.jpg\n",
    "    â”‚   â”œâ”€â”€ 00001.jpg\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ test_0001\n",
    "    â”‚   â”œâ”€â”€ 00000.jpg\n",
    "    â”‚   â”œâ”€â”€ 00001.jpg\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ce7ae9-2137-4d19-a631-5787f24c88f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on <module 'source.dataset' from '/home/stephencha/Hub/soo/source/dataset.py'> dataset...\n",
      "Number of train videos: 2663\n",
      "Number of val videos: 670\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model on {} dataset...\".format(dataset))\n",
    "train_dataset = dataset.VideoDataset(\n",
    "    root_dir=args.dataset_root_dir,\n",
    "    dataset=args.dataset,\n",
    "    split=\"train\",\n",
    "    clip_len=args.clip_len,\n",
    ")\n",
    "val_dataset = dataset.VideoDataset(\n",
    "    root_dir=args.dataset_root_dir,\n",
    "    dataset=args.dataset,\n",
    "    split=\"val\",\n",
    "    clip_len=args.clip_len,\n",
    ")\n",
    "\n",
    "\n",
    "def build_dataset(batch_size):\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=args.num_workers\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, num_workers=args.num_workers\n",
    "    )\n",
    "\n",
    "    trainval_loaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "    trainval_sizes = {x: len(trainval_loaders[x].dataset) for x in [\"train\", \"val\"]}\n",
    "\n",
    "    return trainval_loaders, trainval_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74126a81-da0d-419e-b924-0ff198b6a951",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e70e4-9c38-4d4b-975b-91ba637fa983",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb49a0ed-0ec0-4ef2-8b58-d38db387dfc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import timm.optim.nadam as nadam\n",
    "import torchcontrib\n",
    "from source.focalloss import FocalLoss\n",
    "from source.label_smooth import LabelSmoothSoftmaxCEV2\n",
    "from torch.optim.swa_utils import SWALR\n",
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03973808-9792-4d7c-9273-24380a4fc0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_loss_function(lf):\n",
    "    if lf == \"focal\":\n",
    "        lf = FocalLoss()\n",
    "    elif lf == \"cross_entropy\":\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "    elif lf == \"label_smooth\":\n",
    "        lf = LabelSmoothSoftmaxCEV2()\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedbb057-8ca2-483b-89e0-0fc6fafa9300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(model, opt, lr):\n",
    "    if args.model == \"C3D\":\n",
    "        param = [\n",
    "            {\"params\": C3D_model.get_1x_lr_params(model), \"lr\": lr},\n",
    "            {\"params\": C3D_model.get_10x_lr_params(model), \"lr\": lr * 10},\n",
    "        ]\n",
    "    elif args.model == \"R2Plus1D\":\n",
    "        param = [\n",
    "            {\"params\": R2Plus1D_model.get_1x_lr_params(model), \"lr\": lr},\n",
    "            {\"params\": R2Plus1D_model.get_10x_lr_params(model), \"lr\": lr * 10},\n",
    "        ]\n",
    "    elif args.model == \"R3D\":\n",
    "        param = model.parameters()\n",
    "    elif args.model == \"TimeSformer\":\n",
    "        param = model.parameters()\n",
    "    elif args.model == \"Efficientnet_LSTM\":\n",
    "        param = model.parameters()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if opt == \"sgd\":\n",
    "        optimizer = optim.SGD(param, lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    elif opt == \"adam\":\n",
    "        optimizer = optim.Adam(param, lr=lr, amsgrad=True)\n",
    "    elif opt == \"adamw\":\n",
    "        optimizer = optim.AdamW(param, lr=lr)\n",
    "    elif opt == \"adadelta\":\n",
    "        optimizer = optim.Adadelta(param, lr=lr)\n",
    "    elif opt == \"nadam\":\n",
    "        optimizer = nadam.Nadam(param, lr=lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "241305d1-de1f-4624-95a7-9305767a59cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_schedular(optimizer, sche, epochs, length):\n",
    "    if sche == \"step\":\n",
    "        schedular = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif sche == \"onecycle\":\n",
    "        schedular = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            pct_start=0.1,\n",
    "            div_factor=1e5,\n",
    "            max_lr=0.0001,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=length,\n",
    "        )\n",
    "    elif sche == \"cosineannealingwarmrestarts\":\n",
    "        schedular = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=10, T_mult=2, eta_min=1e-5, last_epoch=-1\n",
    "        )\n",
    "    elif sche == \"swa\":\n",
    "        schedular = SWALR(optimizer, swa_lr=0.01)\n",
    "    return schedular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bf330-61d0-43f2-916f-d33ffa9846f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33282196-0833-4e3c-bdd4-cbc6b2aece55",
   "metadata": {},
   "source": [
    "## Train\n",
    "* epochë§ˆë‹¤ í•™ìŠµê³¼ ê²€ì¦ì„ ì‹¤ì‹œí•œë‹¤.\n",
    "* `./run/run_*` ë””ë ‰í† ë¦¬ì—ì„œ ì €ì¥ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ í™•ì¸í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ea3eba-c69c-4cd7-8761-e52ed17a7c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    if args.wandb:\n",
    "        with wandb.init(config=args, name=MODEL_NAME) as run:  # reinit=True\n",
    "            config = wandb.config\n",
    "    else:\n",
    "        config = args\n",
    "\n",
    "    trainval_loaders, trainval_sizes = build_dataset(config.batch_size)\n",
    "\n",
    "    # standard crossentropy loss for classification\n",
    "    criterion = build_loss_function(config.loss_function)\n",
    "    optimizer = build_optimizer(model, opt=config.optimizer, lr=config.learning_rate)\n",
    "\n",
    "    # the scheduler divides the lr by 10 every 10 epochs\n",
    "    if config.schedular == \"swa\":\n",
    "        optimizer = torchcontrib.optim.SWA(optimizer)\n",
    "\n",
    "    scheduler = build_schedular(\n",
    "        optimizer,\n",
    "        sche=config.schedular,\n",
    "        epochs=config.epochs,\n",
    "        length=len(trainval_loaders[\"train\"]),\n",
    "    )\n",
    "\n",
    "    best_score = 0  # np.Inf\n",
    "    for epoch in range(config.epochs):\n",
    "        # each epoch has a training and validation step\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            start_time = timeit.default_timer()\n",
    "\n",
    "            # reset the running loss and corrects\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # set model to train() or eval() mode depending on whether it is trained\n",
    "            # or being validated. Primarily affects layers such as BatchNorm or Dropout.\n",
    "            if phase == \"train\":\n",
    "                # scheduler.step() is to be called once every epoch during training\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            epoch_labels = []\n",
    "            epoch_preds = []\n",
    "\n",
    "            for inputs, labels in tqdm(trainval_loaders[phase]):\n",
    "                # move inputs and labels to the device the training is taking place on\n",
    "                inputs = Variable(inputs, requires_grad=True).to(device)\n",
    "                labels = Variable(labels).to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                probs = nn.Softmax(dim=1)(outputs)\n",
    "                preds = torch.max(probs, 1)[1]\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_labels.extend(labels.tolist())\n",
    "                epoch_preds.extend(preds.tolist())\n",
    "\n",
    "            epoch_loss = running_loss / trainval_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / trainval_sizes[phase]\n",
    "\n",
    "            epoch_score = f1_score(epoch_preds, epoch_labels, average=\"weighted\")\n",
    "            print(f\"{phase} | EPOCH {epoch} Weighted F1 SCORE: {epoch_score}\")\n",
    "\n",
    "            print(\n",
    "                \"[{}] Epoch: {}/{} Loss: {} Acc: {}\".format(\n",
    "                    phase, epoch + 1, config.epochs, epoch_loss, epoch_acc\n",
    "                )\n",
    "            )\n",
    "            stop_time = timeit.default_timer()\n",
    "            print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")\n",
    "\n",
    "            if args.wandb and phase == \"val\":\n",
    "                wandb.log(\n",
    "                    {\"Weighted F1 Scrore\": epoch_score,}\n",
    "                )\n",
    "\n",
    "            if epoch_score > best_score and phase == \"val\":\n",
    "                print(\n",
    "                    f\"Validation Weighted F1 Score increased ({best_score:.6f} --> {epoch_score:.6f}).  Saving model ...\"\n",
    "                )\n",
    "                model_path = os.path.join(\n",
    "                    SAVE_DIR,\n",
    "                    \"models\",\n",
    "                    saveName\n",
    "                    + \"_epoch-\"\n",
    "                    + str(epoch)\n",
    "                    + \"_epoch_score-{:.6f}.pt\".format(epoch_score)\n",
    "                    + \".pth.tar\",\n",
    "                )\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"opt_dict\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    model_path,\n",
    "                )\n",
    "                print(\"Save model at {}\\n\".format(model_path))\n",
    "                best_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d82a680-4662-4e49-9491-2675917257b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/134 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 3, 3, 3], but got 5-dimensional input of size [20, 3, 16, 113, 113] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-51f1e152ff86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-baf0e11d8411>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Hub/soo/source/model/Efficientnet_LSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda3/lib/python3.8/site-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 3, 3, 3], but got 5-dimensional input of size [20, 3, 16, 113, 113] instead"
     ]
    }
   ],
   "source": [
    "if args.wandb:\n",
    "    wandb.agent(sweep_id, train, count=args.count)\n",
    "    run.finish()\n",
    "else:\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188bc83-1b3c-4683-8361-524e183600e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d9c47-78f9-4f29-bd08-08f437cbb905",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aed22a-7df4-4978-8ad1-0409f74e3273",
   "metadata": {},
   "source": [
    "## Inference\n",
    "* ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ìƒì„±ëœ `submit.csv` íŒŒì¼ì„ í™•ì¸í•˜ê³ , ì œì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1b58c-cd16-49f9-8457-00137f97cb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cls_li = [\n",
    "    \"driveway_walk\",\n",
    "    \"fall_down\",\n",
    "    \"fighting\",\n",
    "    \"jay_walk\",\n",
    "    \"normal\",\n",
    "    \"putup_umbrella\",\n",
    "    \"ride_cycle\",\n",
    "    \"ride_kick\",\n",
    "    \"ride_moto\",\n",
    "]\n",
    "\n",
    "DATA_DIR = args.dataset_root_dir  # os.path.join(PROJECT_DIR, '')\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96e421-c572-4ba1-b588-9163dc9ea749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    model_path, map_location=lambda storage, loc: storage\n",
    ")  # Load all tensors onto the CPU\n",
    "\n",
    "print(f\"Initializing weights from: {model_path.split('/')[-1]}...\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "print(\"Total params: %.2fM\" % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "\n",
    "print(\"Model Inference on {} dataset...\".format(dataset))\n",
    "\n",
    "if os.path.isdir(os.path.join(DATA_DIR, \"test_processed\")):\n",
    "    preprocess = False\n",
    "else:\n",
    "    preprocess = True\n",
    "\n",
    "test_dataset = dataset.TestDataset(root_dir=args.dataset_root_dir, dataset=dataset, clip_len=16, preprocess=preprocess)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_li = []\n",
    "for inputs in tqdm(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    probs = nn.Softmax(dim=1)(outputs)\n",
    "    preds = torch.max(probs, 1)[1]\n",
    "    pred_li.extend(preds.tolist())\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e3be6-5edf-451b-9128-b3d541565bca",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bfa86-4dac-4a81-9414-2f4a8a8bea71",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9ee17-ec0a-401e-a295-f00dc8d8f316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission[\"class\"] = [cls_li[int(pred)] for pred in pred_li]\n",
    "sample_submission.to_csv(\"submit_{}.csv\".format(model_path.split('/')[-1]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37631998-b59e-4009-b16b-f50b855ae6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919bac1-984f-4fed-841f-4f60f2471595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34347890-f4dc-4055-bde2-a6d489794f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacdf25-e089-436a-911c-8a1652463ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
