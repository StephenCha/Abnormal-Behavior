{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3b446a-f36f-46ff-b4b7-9dca78edbe14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# íŒêµ AI Challenge\n",
    "> ì°¸ì¹˜ê¹€ì¹˜ì°Œê°œíŒ€<br>\n",
    "> íŒ€ì¥ ì†ì°¬ì˜, íŒ€ì› ê¹€ë¯¼ì • ê¹€í•˜ë¦¼ ì´ë‘í˜„ ì°¨í˜„ìˆ˜\n",
    "* ê³¼ì œëª… : [ì•„ë™ ë° êµí†µì•½ì ë³´í˜¸ë¥¼ ìœ„í•œ ì–´ë¦°ì´ ë„ë¡œë³´í–‰ ìœ„í—˜í–‰ë™ ë¶„ë¥˜ ê³¼ì œ]\n",
    "* ê³¼ì œ ë§í¬ : https://www.aiconnect.kr/main/competition/privateDetail/200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c399d1e-7303-4345-a7ae-2cb65b7dd813",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342062d-42a6-49df-a478-880e685c1d1b",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30321103-75de-4d8d-815e-c066da74a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import warnings\n",
    "\n",
    "import easydict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Others\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Customized Source Python Files\n",
    "import source.dataset as dataset\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score\n",
    "from source.model import C3D_model, R2Plus1D_model, R3D_model\n",
    "from source.model.utils.vit import TimeSformer\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e82ff94-f86c-4ea3-86f0-6fcb93218a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"main\"\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "#%env WANDB_SILENT=True\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dcbf89-ca95-4ab0-af6a-0bae98508f28",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d7d64-89ef-43fa-8da9-6c4cfd5c6ccb",
   "metadata": {},
   "source": [
    "## Parameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8f51f7-3dc6-4d72-97b9-9494f385784c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {\n",
    "        \"experiment\": \"exp1 TimeSformer\",  # ë§¤ë²ˆ ë°”ê¿”ì¤€ë‹¤.\n",
    "        \"wandb\": True,\n",
    "        \"randomseed\": False,\n",
    "        \"dataset\": \"kids\",  # Options: hmdb51 or ucf101 or `kids`\n",
    "        \"dataset_root_dir\": \"./dataset\",\n",
    "        \"project_dir\": os.getcwd(),\n",
    "        \"model_dir\": \"./pretrained/TimeSformer_divST_8x32_224_K400.pyth\",\n",
    "        \"snapshot\": 20,  # Store a model every snapshot epochs\n",
    "        \"clip_len\": 16,\n",
    "        \"num_workers\": 4,\n",
    "        \"save_epoch\": 5,  # SAVE, View\n",
    "        \"model\": \"TimeSformer\",  # Options: C3D or R2Plus1D or R3D\n",
    "        \"attention_type\": \"divided_space_time\",\n",
    "        \"num_frames\": 19,\n",
    "        \"img_size\": 224,\n",
    "        \"count\": 20,  # how many repeat for wandb\n",
    "    }\n",
    ")\n",
    "NAME_ELEMENTS = [args.model, time.strftime(\"%m%d_%H%M\", time.localtime(time.time()))]\n",
    "MODEL_NAME = \"_\".join(NAME_ELEMENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c96ba-54b1-4adf-a0b7-7c573a000900",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce28948-bf1e-46f5-80e1-59a3171c8711",
   "metadata": {},
   "source": [
    "## W&B & Randomseed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddea16d-9f96-4822-8ab0-5da0007c7890",
   "metadata": {},
   "source": [
    "### ğŸš€ Setup\n",
    "\n",
    "Start out by installing the experiment tracking library and setting up your free W&B account:<br>\n",
    "`.login()` so you can log metrics to your projects<br>\n",
    "If you've never used Weights & Biases before,\n",
    "the call to `login` will give you a link to sign up for an account.\n",
    "W&B is free to use for personal and academic projects!<br>\n",
    "### ğŸ‘ˆ Pick a `method`\n",
    "The first thing we need to define is the `method`\n",
    "for choosing new parameter values.\n",
    "\n",
    "We provide the following search `methods`:\n",
    "*   **`grid` Search** â€“ Iterate over every combination of hyperparameter values.\n",
    "Very effective, but can be computationally costly.\n",
    "*   **`random` Search** â€“ Select each new combination at random according to provided `distribution`s. Surprisingly effective!\n",
    "*   **`bayesian` Search** â€“ Create a probabilistic model of metric score as a function of the hyperparameters, and choose parameters with high probability of improving the metric. Works well for small numbers of continuous parameters but scales poorly.\n",
    "\n",
    "We'll stick with `random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500451d1-d593-4134-8660-1ed8417f44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstephencha\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: x0zq7vyf\n",
      "Sweep URL: https://wandb.ai/stephencha/tunakimchi/sweeps/x0zq7vyf\n"
     ]
    }
   ],
   "source": [
    "if args.wandb:\n",
    "    wandb.login()\n",
    "    sweep_config = {\n",
    "        \"name\": args.experiment,\n",
    "        \"method\": \"bayes\",  # grid, bayesian, random\n",
    "        \"metric\": {\n",
    "            \"name\": \"Weighted F1 Scrore\",\n",
    "            \"goal\": \"maximize\",\n",
    "            # 'target': 'goal value for the metric you're optimizing, for example : 0.01'\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            \"epochs\": {\"values\": [10, 15, 20]},\n",
    "            \"learning_rate\": {\"distribution\": \"uniform\", \"min\": 1e-4, \"max\": 5e-2,},\n",
    "            \"optimizer\": {\"values\": [\"adam\", \"sgd\", \"adamw\", \"adadelta\", \"nadam\"]},\n",
    "            \"loss_function\": {\"values\": [\"focal\", \"cross_entropy\", \"label_smooth\"]},\n",
    "            \"schedular\": {\n",
    "                \"values\": [\"step\", \"onecycle\", \"cosineannealingwarmrestarts\", \"swa\"]\n",
    "            },\n",
    "            \"batch_size\": {\"values\": [10, 15]},\n",
    "        },\n",
    "    }\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"tunakimchi\")\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"main.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700f2509-456d-4abe-85e6-93b2bfad33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.randomseed:\n",
    "    torch.manual_seed(args.randomseed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(args.randomseed)\n",
    "    random.seed(args.randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2630c-ae35-4fab-955b-471ed3945dc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b9176-d0bb-4eae-8d56-508bc4c4f2ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce6b8e8-4f96-457f-b8ad-5bae1c3e4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available else revert to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device being used:\", device)\n",
    "\n",
    "if args.dataset == \"hmdb51\":\n",
    "    num_classes = 51\n",
    "elif args.dataset == \"ucf101\":\n",
    "    num_classes = 101\n",
    "elif args.dataset == \"kids\":\n",
    "    num_classes = 9\n",
    "else:\n",
    "    print(\"We only implemented hmdb and ucf datasets.\")\n",
    "    raise NotImplementedError\n",
    "\n",
    "saveName = args.model + \"-\" + args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c51ef8e-43b7-4f2f-b2f5-2dfcb43fe595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build run dir\n",
    "runs = sorted(glob.glob(os.path.join(args.project_dir, \"run\", \"run_*\")))\n",
    "run_id = int(runs[-1].split(\"_\")[-1]) + 1 if runs else 0\n",
    "\n",
    "SAVE_DIR = os.path.join(args.project_dir, \"run\", \"run_\" + str(run_id))\n",
    "model_save_dir = os.path.join(SAVE_DIR, \"models\")\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "if args.model == \"C3D\":\n",
    "    model = C3D_model.C3D(model_dir=model_dir, num_classes=num_classes, pretrained=True)\n",
    "    train_params = [\n",
    "        {\"params\": C3D_model.get_1x_lr_params(model), \"lr\": lr},\n",
    "        {\"params\": C3D_model.get_10x_lr_params(model), \"lr\": lr * 10},\n",
    "    ]\n",
    "\n",
    "elif args.model == \"R2Plus1D\":\n",
    "    model = R2Plus1D_model.R2Plus1DClassifier(\n",
    "        num_classes=num_classes, layer_sizes=(2, 2, 2, 2)\n",
    "    )\n",
    "    train_params = [\n",
    "        {\"params\": R2Plus1D_model.get_1x_lr_params(model), \"lr\": lr},\n",
    "        {\"params\": R2Plus1D_model.get_10x_lr_params(model), \"lr\": lr * 10},\n",
    "    ]\n",
    "\n",
    "elif args.model == \"R3D\":\n",
    "    model = R3D_model.R3DClassifier(num_classes=num_classes, layer_sizes=(2, 2, 2, 2))\n",
    "    train_params = model.parameters()\n",
    "\n",
    "elif args.model == \"TimeSformer\":\n",
    "    model = TimeSformer(\n",
    "        img_size=args.img_size,\n",
    "        num_classes=num_classes,\n",
    "        num_frames=args.num_frames,\n",
    "        attention_type=args.attention_type,\n",
    "        pretrained_model=args.model_dir,\n",
    "    )\n",
    "    train_params = model.parameters()\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247d8a66-1376-4ac5-89a3-9676f357c79c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TimeSformer from scratch...\n",
      "Total params: 121.27M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeSformer(\n",
       "  (model): VisionTransformer(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (time_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=768, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training {} from scratch...\".format(args.model))\n",
    "print(\"Total params: %.2fM\" % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "# model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45ea77-50a9-47fd-97f5-d7a91a69794a",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bade0-24b9-4ba7-86b5-36832a4fe055",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset Preprocessing and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37c179-0e8a-4a8b-bcf2-bb83af5c586c",
   "metadata": {},
   "source": [
    "* ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "ì›í™œí•œ ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµì„ ìœ„í•˜ì—¬ `dataset` ë””ë ‰í† ë¦¬ ì•ˆì— ë‹¤ìŒê³¼ ê°™ì´ ê²½ë¡œë¥¼ ì„¤ì •í•˜ì—¬ ë°ì´í„°ë¥¼ ì €ì¥í•´ì•¼í•œë‹¤.<br>\n",
    "train ë°ì´í„°ì…‹ì€ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë³„ë„ì˜ ë””ë ‰í† ë¦¬ì— ë¹„ë””ì˜¤ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì €ì¥í•´ì•¼ í•˜ëŠ”ë°, arrangement.ipynbë¥¼ ì´ìš©í•˜ë©´ ë°”ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥ì‹œì¼œì¤€ë‹¤.\n",
    "\n",
    "```\n",
    "dataset\n",
    "â”œâ”€â”€ label\n",
    "â”‚   â””â”€â”€ kids_labels\n",
    "â”œâ”€â”€ train\n",
    "â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0003.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”œâ”€â”€ fall_down\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0002.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ fighting\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0056.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   ...\n",
    "â””â”€â”€ test (ê³µê°œê°€ ì•ˆë˜ì–´ìˆë‹¤)\n",
    "    â”œâ”€â”€ test_0000.mp4\n",
    "    â”œâ”€â”€ test_0000.mp4\n",
    "    â”œâ”€â”€ test_0000.mp4\n",
    "    â”œâ”€â”€ ...\n",
    "```\n",
    "\n",
    "í•™ìŠµ ë° ì¶”ë¡  ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ê°ê° train_processed, test_processed ë””ë ‰í† ë¦¬ê°€ ë‹¤ìŒê³¼ ê°™ì´ ìƒì„±ëœë‹¤.<br>\n",
    "ì´ëŠ” dataset.pyë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ ë˜ë‚˜, êµ³ì´ í•  í•„ìš”ëŠ” ì—†ë‹¤.<br>\n",
    "ì „ì²˜ë¦¬ì—ì„œëŠ” ë¹„ë””ì˜¤ì—ì„œ 16í”„ë ˆì„ì„ ìƒ˜í”Œë§í•œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¹„ë””ì˜¤ íŒŒì¼ëª… ë””ë ‰í† ë¦¬ì— ë³„ë„ë¡œ ì €ì¥í•˜ëŠ” ê³¼ì •ì´ ìˆ˜í–‰ëœë‹¤.\n",
    "```\n",
    "dataset\n",
    "â”œâ”€â”€ label\n",
    "â”‚   â””â”€â”€ kids_labels\n",
    "â”œâ”€â”€ train\n",
    "â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0003.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”œâ”€â”€ fall_down\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0002.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ fighting\n",
    "â”‚   â”‚   â”œâ”€â”€ train_0056.mp4\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   ...\n",
    "â”‚\n",
    "â”œâ”€â”€ train_processed\n",
    "â”‚   â”œâ”€â”€ train\n",
    "â”‚   â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ train_0003\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00000.jpg\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00001.jpg\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ val\n",
    "â”‚   â”‚   â”œâ”€â”€ driveway_walk\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ train_0004\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00000.jpg\n",
    "â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00001.jpg\n",
    "â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚\n",
    "â”œâ”€â”€ test\n",
    "â”‚   â”œâ”€â”€ test_0000.mp4\n",
    "â”‚   â”œâ”€â”€ test_0000.mp4\n",
    "â”‚   â”œâ”€â”€ test_0000.mp4\n",
    "â”‚   â””â”€â”€ ...\n",
    "â”‚\n",
    "â””â”€â”€ test_processed\n",
    "    â”œâ”€â”€ test_0000\n",
    "    â”‚   â”œâ”€â”€ 00000.jpg\n",
    "    â”‚   â”œâ”€â”€ 00001.jpg\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ test_0001\n",
    "    â”‚   â”œâ”€â”€ 00000.jpg\n",
    "    â”‚   â”œâ”€â”€ 00001.jpg\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â”œâ”€â”€ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ce7ae9-2137-4d19-a631-5787f24c88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on <module 'source.dataset' from '/home/stephencha/Hub/soo/source/dataset.py'> dataset...\n",
      "Number of train videos: 2663\n",
      "Number of val videos: 670\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model on {} dataset...\".format(dataset))\n",
    "train_dataset = dataset.VideoDataset(\n",
    "    root_dir=args.dataset_root_dir,\n",
    "    dataset=args.dataset,\n",
    "    split=\"train\",\n",
    "    clip_len=args.clip_len,\n",
    ")\n",
    "val_dataset = dataset.VideoDataset(\n",
    "    root_dir=args.dataset_root_dir,\n",
    "    dataset=args.dataset,\n",
    "    split=\"val\",\n",
    "    clip_len=args.clip_len,\n",
    ")\n",
    "\n",
    "\n",
    "def build_dataset(batch_size):\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=args.num_workers\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, num_workers=args.num_workers\n",
    "    )\n",
    "\n",
    "    trainval_loaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "    trainval_sizes = {x: len(trainval_loaders[x].dataset) for x in [\"train\", \"val\"]}\n",
    "\n",
    "    return trainval_loaders, trainval_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74126a81-da0d-419e-b924-0ff198b6a951",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e70e4-9c38-4d4b-975b-91ba637fa983",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb49a0ed-0ec0-4ef2-8b58-d38db387dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm.optim.nadam as nadam\n",
    "import torchcontrib\n",
    "from source.focalloss import FocalLoss\n",
    "from source.label_smooth import LabelSmoothSoftmaxCEV2\n",
    "from torch.optim.swa_utils import SWALR\n",
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03973808-9792-4d7c-9273-24380a4fc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss_function(lf):\n",
    "    if lf == \"focal\":\n",
    "        lf = FocalLoss()\n",
    "    elif lf == \"cross_entropy\":\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "    elif lf == \"label_smooth\":\n",
    "        lf = LabelSmoothSoftmaxCEV2()\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedbb057-8ca2-483b-89e0-0fc6fafa9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(model, opt, lr):\n",
    "    if args.model == \"C3D\":\n",
    "        param = [\n",
    "            {\"params\": C3D_model.get_1x_lr_params(model), \"lr\": lr},\n",
    "            {\"params\": C3D_model.get_10x_lr_params(model), \"lr\": lr * 10},\n",
    "        ]\n",
    "    elif args.model == \"R2Plus1D\":\n",
    "        param = [\n",
    "            {\"params\": R2Plus1D_model.get_1x_lr_params(model), \"lr\": lr},\n",
    "            {\"params\": R2Plus1D_model.get_10x_lr_params(model), \"lr\": lr * 10},\n",
    "        ]\n",
    "    elif args.model == \"R3D\":\n",
    "        param = model.parameters()\n",
    "    elif args.model == \"TimeSformer\":\n",
    "        param = model.parameters()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if opt == \"sgd\":\n",
    "        optimizer = optim.SGD(param, lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    elif opt == \"adam\":\n",
    "        optimizer = optim.Adam(param, lr=lr, amsgrad=True)\n",
    "    elif opt == \"adamw\":\n",
    "        optimizer = optim.AdamW(param, lr=lr)\n",
    "    elif opt == \"adadelta\":\n",
    "        optimizer = optim.Adadelta(param, lr=lr)\n",
    "    elif opt == \"nadam\":\n",
    "        optimizer = nadam.Nadam(param, lr=lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "241305d1-de1f-4624-95a7-9305767a59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_schedular(optimizer, sche, epochs, length):\n",
    "    if sche == \"step\":\n",
    "        schedular = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif sche == \"onecycle\":\n",
    "        schedular = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            pct_start=0.1,\n",
    "            div_factor=1e5,\n",
    "            max_lr=0.0001,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=length,\n",
    "        )\n",
    "    elif sche == \"cosineannealingwarmrestarts\":\n",
    "        schedular = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=10, T_mult=2, eta_min=1e-5, last_epoch=-1\n",
    "        )\n",
    "    elif sche == \"swa\":\n",
    "        schedular = SWALR(optimizer, swa_lr=0.01)\n",
    "    return schedular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bf330-61d0-43f2-916f-d33ffa9846f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33282196-0833-4e3c-bdd4-cbc6b2aece55",
   "metadata": {},
   "source": [
    "## Train\n",
    "* epochë§ˆë‹¤ í•™ìŠµê³¼ ê²€ì¦ì„ ì‹¤ì‹œí•œë‹¤.\n",
    "* `./run/run_*` ë””ë ‰í† ë¦¬ì—ì„œ ì €ì¥ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ í™•ì¸í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ea3eba-c69c-4cd7-8761-e52ed17a7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    with wandb.init(config=args, name=MODEL_NAME) as run:  # reinit=True\n",
    "        config = wandb.config\n",
    "\n",
    "        trainval_loaders, trainval_sizes = build_dataset(config.batch_size)\n",
    "\n",
    "        # standard crossentropy loss for classification\n",
    "        criterion = build_loss_function(config.loss_function)\n",
    "        optimizer = build_optimizer(\n",
    "            model, opt=config.optimizer, lr=config.learning_rate\n",
    "        )\n",
    "\n",
    "        # the scheduler divides the lr by 10 every 10 epochs\n",
    "        if config.schedular == \"swa\":\n",
    "            optimizer = torchcontrib.optim.SWA(optimizer)\n",
    "\n",
    "        scheduler = build_schedular(\n",
    "            optimizer,\n",
    "            sche=config.schedular,\n",
    "            epochs=config.epochs,\n",
    "            length=len(trainval_loaders[\"train\"]),\n",
    "        )\n",
    "\n",
    "        best_score = np.Inf\n",
    "        for epoch in range(config.epochs):\n",
    "            # each epoch has a training and validation step\n",
    "            for phase in [\"train\", \"val\"]:\n",
    "                start_time = timeit.default_timer()\n",
    "\n",
    "                # reset the running loss and corrects\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0.0\n",
    "\n",
    "                # set model to train() or eval() mode depending on whether it is trained\n",
    "                # or being validated. Primarily affects layers such as BatchNorm or Dropout.\n",
    "                if phase == \"train\":\n",
    "                    # scheduler.step() is to be called once every epoch during training\n",
    "                    scheduler.step()\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                epoch_labels = []\n",
    "                epoch_preds = []\n",
    "\n",
    "                for inputs, labels in tqdm(trainval_loaders[phase]):\n",
    "                    # move inputs and labels to the device the training is taking place on\n",
    "                    inputs = Variable(inputs, requires_grad=True).to(device)\n",
    "                    labels = Variable(labels).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        outputs = model(inputs)\n",
    "                    else:\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(inputs)\n",
    "\n",
    "                    probs = nn.Softmax(dim=1)(outputs)\n",
    "                    preds = torch.max(probs, 1)[1]\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                    epoch_labels.extend(labels.tolist())\n",
    "                    epoch_preds.extend(preds.tolist())\n",
    "\n",
    "                epoch_loss = running_loss / trainval_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / trainval_sizes[phase]\n",
    "\n",
    "                epoch_score = f1_score(epoch_preds, epoch_labels, average=\"weighted\")\n",
    "                print(f\"{phase} | EPOCH {epoch} Weighted F1 SCORE: {epoch_score}\")\n",
    "\n",
    "                print(\n",
    "                    \"[{}] Epoch: {}/{} Loss: {} Acc: {}\".format(\n",
    "                        phase, epoch + 1, config.epochs, epoch_loss, epoch_acc\n",
    "                    )\n",
    "                )\n",
    "                stop_time = timeit.default_timer()\n",
    "                print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")\n",
    "\n",
    "                if epoch_score < best_score:\n",
    "                    print(\n",
    "                        f\"Validation Weighted F1 Score decreased ({best_score:.6f} --> {epoch_score:.6f}).  Saving model ...\"\n",
    "                    )\n",
    "                    path_dir = [SAVE_DIR, \"{:.6f}.pt\".format(epoch_score)]\n",
    "                    torch.save(model.state_dict(), os.path.join(*path_dir))\n",
    "                    best_score = epoch_score\n",
    "\n",
    "                if args.wandb and phase == \"val\":\n",
    "                    wandb.log(\n",
    "                        {\"Weighted F1 Scrore\": epoch_score,}\n",
    "                    )\n",
    "\n",
    "            if epoch % args.save_epoch == (args.save_epoch - 1):\n",
    "                model_path = os.path.join(\n",
    "                    SAVE_DIR, \"models\", saveName + \"_epoch-\" + str(epoch) + \".pth.tar\"\n",
    "                )\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"opt_dict\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    model_path,\n",
    "                )\n",
    "                print(\"Save model at {}\\n\".format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6092ff-f906-4983-9968-7c20be9a2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 702r9l3a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04401988009096347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: cross_entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tschedular: cosineannealingwarmrestarts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/stephencha/tunakimchi/runs/702r9l3a?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7f7073d1a3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178/178 [17:42<00:00,  5.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | EPOCH 0 Weighted F1 SCORE: 0.33650511296900487\n",
      "[train] Epoch: 1/10 Loss: 4.0444980202605745 Acc: 0.2827638002253098\n",
      "Execution time: 1062.3134663130004\n",
      "\n",
      "Validation Weighted F1 Score decreased (inf --> 0.336505).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:07<00:00,  6.04it/s]\n",
      "  0%|          | 0/178 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val | EPOCH 0 Weighted F1 SCORE: 0.5044642857142857\n",
      "[val] Epoch: 1/10 Loss: 1.9998585510609754 Acc: 0.3373134328358209\n",
      "Execution time: 7.453054837000309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 36/178 [03:35<14:09,  5.98s/it]"
     ]
    }
   ],
   "source": [
    "if args.wandb:\n",
    "    wandb.agent(sweep_id, train, count=args.count)\n",
    "else:\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188bc83-1b3c-4683-8361-524e183600e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.wandb:\n",
    "    run.finish()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d9c47-78f9-4f29-bd08-08f437cbb905",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aed22a-7df4-4978-8ad1-0409f74e3273",
   "metadata": {},
   "source": [
    "## Inference\n",
    "* ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ìƒì„±ëœ `submit.csv` íŒŒì¼ì„ í™•ì¸í•˜ê³ , ì œì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1b58c-cd16-49f9-8457-00137f97cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_li = [\n",
    "    \"driveway_walk\",\n",
    "    \"fall_down\",\n",
    "    \"fighting\",\n",
    "    \"jay_walk\",\n",
    "    \"normal\",\n",
    "    \"putup_umbrella\",\n",
    "    \"ride_cycle\",\n",
    "    \"ride_kick\",\n",
    "    \"ride_moto\",\n",
    "]\n",
    "\n",
    "DATA_DIR = args.dataset_root_dir  # os.path.join(PROJECT_DIR, '')\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cef8bf-9465-44c5-b32f-c5265dc8a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    model_path, map_location=lambda storage, loc: storage\n",
    ")  # Load all tensors onto the CPU\n",
    "print(f\"Initializing weights from: {model_path.split('/')[-1]}...\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "print(\"Total params: %.2fM\" % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "\n",
    "print(\"Model Inference on {} dataset...\".format(dataset))\n",
    "\n",
    "if os.path.isdir(os.path.join(DATA_DIR, \"test_processed\")):\n",
    "    preprocess = False\n",
    "else:\n",
    "    preprocess = True\n",
    "\n",
    "test_dataset = dataset.TestDataset(dataset=dataset, clip_len=16, preprocess=preprocess)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_li = []\n",
    "for inputs in tqdm(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    probs = nn.Softmax(dim=1)(outputs)\n",
    "    preds = torch.max(probs, 1)[1]\n",
    "    pred_li.extend(preds.tolist())\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")\n",
    "\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission[\"class\"] = [cls_li[int(pred)] for pred in pred_li]\n",
    "sample_submission.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37631998-b59e-4009-b16b-f50b855ae6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919bac1-984f-4fed-841f-4f60f2471595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34347890-f4dc-4055-bde2-a6d489794f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacdf25-e089-436a-911c-8a1652463ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
